{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "341ec0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q opentelemetry-api\n",
    "%pip install -q opentelemetry-sdk \n",
    "%pip install -q opentelemetry-exporter-otlp-proto-grpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66de22b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-step reasoning trace generated. Check Jaeger UI.\n"
     ]
    }
   ],
   "source": [
    "# save as reasoning_flow_trace.py\n",
    "from opentelemetry import trace\n",
    "from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.sdk.resources import Resource\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.sdk.trace.export import BatchSpanProcessor\n",
    "import time\n",
    "\n",
    "# Setup\n",
    "resource = Resource(attributes={\"service.name\": \"reasoning-agent\"})\n",
    "provider = TracerProvider(resource=resource)\n",
    "exporter = OTLPSpanExporter(endpoint=\"localhost:4317\", insecure=True)\n",
    "processor = BatchSpanProcessor(exporter)\n",
    "provider.add_span_processor(processor)\n",
    "trace.set_tracer_provider(provider)\n",
    "tracer = trace.get_tracer(\"reasoning-tracer\")\n",
    "\n",
    "# Main agent span\n",
    "with tracer.start_as_current_span(\n",
    "    \"chain_of_thought\",\n",
    "    attributes={\n",
    "        \"gen_ai.operation.name\": \"agent\",\n",
    "        \"gen_ai.system\": \"openai\",\n",
    "        \"gen_ai.agent.name\": \"reasoning-agent\",\n",
    "        \"gen_ai.request.model\": \"gpt-4o\"\n",
    "    }\n",
    "):\n",
    "    # Initial problem analysis\n",
    "    with tracer.start_as_current_span(\n",
    "        \"step1_analyze\",\n",
    "        attributes={\"gen_ai.operation.name\": \"thinking\"}\n",
    "    ):\n",
    "        current_span = trace.get_current_span()\n",
    "        current_span.add_event(\n",
    "            \"reasoning_step\", \n",
    "            attributes={\"thought\": \"Let me analyze this math problem step by step.\"}\n",
    "        )\n",
    "        time.sleep(0.1)  # Simulate processing time\n",
    "    \n",
    "    # Generate potential solutions\n",
    "    with tracer.start_as_current_span(\n",
    "        \"step2_generate_options\",\n",
    "        attributes={\"gen_ai.operation.name\": \"thinking\"}\n",
    "    ):\n",
    "        current_span = trace.get_current_span()\n",
    "        current_span.add_event(\n",
    "            \"reasoning_step\", \n",
    "            attributes={\"thought\": \"I need to find the derivative of x²sin(x)\"}\n",
    "        )\n",
    "        time.sleep(0.1)  # Simulate processing time\n",
    "    \n",
    "    # Evaluate options\n",
    "    with tracer.start_as_current_span(\n",
    "        \"step3_evaluate\",\n",
    "        attributes={\"gen_ai.operation.name\": \"thinking\"}\n",
    "    ):\n",
    "        current_span = trace.get_current_span()\n",
    "        current_span.add_event(\n",
    "            \"reasoning_step\", \n",
    "            attributes={\"thought\": \"Using the product rule: d/dx[x²sin(x)] = 2xsin(x) + x²cos(x)\"}\n",
    "        )\n",
    "        time.sleep(0.1)  # Simulate processing time\n",
    "    \n",
    "    # Final decision\n",
    "    with tracer.start_as_current_span(\n",
    "        \"step4_decide\",\n",
    "        attributes={\"gen_ai.operation.name\": \"thinking\"}\n",
    "    ):\n",
    "        current_span = trace.get_current_span()\n",
    "        current_span.add_event(\n",
    "            \"reasoning_step\", \n",
    "            attributes={\"thought\": \"The final answer is 2xsin(x) + x²cos(x)\"}\n",
    "        )\n",
    "        time.sleep(0.1)  # Simulate processing time\n",
    "\n",
    "print(\"Multi-step reasoning trace generated. Check Jaeger UI.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5d6014d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool usage trace generated. Check Jaeger UI.\n"
     ]
    }
   ],
   "source": [
    "# save as tool_usage_trace.py\n",
    "from opentelemetry import trace\n",
    "from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.sdk.resources import Resource\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.sdk.trace.export import BatchSpanProcessor\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Setup\n",
    "resource = Resource(attributes={\"service.name\": \"agent-with-tools\"})\n",
    "provider = TracerProvider(resource=resource)\n",
    "exporter = OTLPSpanExporter(endpoint=\"localhost:4317\", insecure=True)\n",
    "processor = BatchSpanProcessor(exporter)\n",
    "provider.add_span_processor(processor)\n",
    "trace.set_tracer_provider(provider)\n",
    "tracer = trace.get_tracer(\"tool-tracer\")\n",
    "\n",
    "# Main agent operation\n",
    "with tracer.start_as_current_span(\n",
    "    \"chat gpt-4o\",\n",
    "    attributes={\n",
    "        \"gen_ai.system\": \"openai\",\n",
    "        \"gen_ai.operation.name\": \"chat\",\n",
    "        \"gen_ai.request.model\": \"gpt-4o\"\n",
    "    }\n",
    "):\n",
    "    # Add event for the user message\n",
    "    current_span = trace.get_current_span()\n",
    "    current_span.add_event(\n",
    "        \"gen_ai.user.message\", \n",
    "        attributes={\"content\": \"What's the weather in Paris?\"}\n",
    "    )\n",
    "    \n",
    "    # Add event for the assistant deciding to use a tool\n",
    "    current_span.add_event(\n",
    "        \"gen_ai.assistant.message\", \n",
    "        attributes={\n",
    "            # Either omit the content field entirely or use an empty string\n",
    "            # \"content\": \"\",  # Empty content instead of None\n",
    "            # Alternatively, simply omit the content field:\n",
    "            \"tool_calls\": json.dumps([{\n",
    "                \"id\": \"call_abc123\",\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"get_weather\",\n",
    "                    \"arguments\": '{\"location\":\"Paris\"}'\n",
    "                }\n",
    "            }])\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Add a child span for the tool execution\n",
    "    with tracer.start_as_current_span(\n",
    "        \"execute_tool get_weather\",\n",
    "        attributes={\n",
    "            \"gen_ai.operation.name\": \"execute_tool\",\n",
    "            \"gen_ai.tool.name\": \"get_weather\",\n",
    "            \"gen_ai.tool.call.id\": \"call_abc123\"\n",
    "        }\n",
    "    ):\n",
    "        # Simulate tool execution\n",
    "        time.sleep(0.2)\n",
    "        \n",
    "        # Add tool response event\n",
    "        tool_span = trace.get_current_span()\n",
    "        tool_span.add_event(\n",
    "            \"gen_ai.tool.message\", \n",
    "            attributes={\n",
    "                \"content\": \"rainy, 57°F\",\n",
    "                \"id\": \"call_abc123\",\n",
    "                \"role\": \"tool\"\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    # Add event for the final assistant response\n",
    "    current_span.add_event(\n",
    "        \"gen_ai.assistant.message\", \n",
    "        attributes={\n",
    "            \"content\": \"The weather in Paris is rainy with a temperature of 57°F.\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"Tool usage trace generated. Check Jaeger UI.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fd475c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
